{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deSpeckNet_TEST.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adugnag/deSpeckNet-TF-GEE/blob/main/notebooks/test.ipynb)"
      ],
      "metadata": {
        "id": "OO-VHqjyPMNh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MJ4kW1pEhwP"
      },
      "source": [
        "# Setup software libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neIa46CpciXq"
      },
      "source": [
        "# Cloud authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jat01FEoUMqg"
      },
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RnZzcYhcpsQ"
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1hFdpBQfyhN"
      },
      "source": [
        "# Folium setup.\n",
        "import folium\n",
        "print(folium.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZznHgcjO8fP"
      },
      "source": [
        "#@title Helper functions\n",
        "def lin_to_db(image):\n",
        "    \"\"\"\n",
        "    Convert backscatter from linear to dB.\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : ee.Image\n",
        "        Image to convert \n",
        "    Returns\n",
        "    -------\n",
        "    ee.Image\n",
        "        output image\n",
        "    \"\"\"\n",
        "    bandNames = image.bandNames().remove('angle')\n",
        "    db = ee.Image.constant(10).multiply(image.select(bandNames).log10()).rename(bandNames)\n",
        "    return image.addBands(db, None, True)\n",
        "\n",
        "\n",
        "def s1_prep(params):\n",
        "    \"\"\"\n",
        "    Applies preprocessing to a collection of S1 images to return an analysis ready sentinel-1 data. \n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    POLARIZATION = params['POLARIZATION']\n",
        "    FORMAT = params['FORMAT']\n",
        "    START_DATE = params['START_DATE']\n",
        "    STOP_DATE = params['STOP_DATE']\n",
        "    ORBIT = params['ORBIT']\n",
        "    RELATIVE_ORBIT_NUMBER = params['RELATIVE_ORBIT_NUMBER']\n",
        "    ROI = params['ROI']\n",
        "    CLIP_TO_ROI = params['CLIP_TO_ROI']\n",
        "\n",
        "    ###########################################\n",
        "    # 0. CHECK PARAMETERS\n",
        "    ###########################################\n",
        "    \n",
        "    if POLARIZATION is None: POLARIZATION = 'VVVH'\n",
        "    if FORMAT is None: FORMAT = 'DB' \n",
        "    if ORBIT is None: ORBIT = 'DESCENDING' \n",
        "    \n",
        "    \n",
        "    pol_required = ['VV', 'VH', 'VVVH']\n",
        "    if (POLARIZATION not in pol_required):\n",
        "        raise ValueError(\"ERROR!!! Parameter POLARIZATION not correctly defined\")\n",
        "\n",
        "    \n",
        "    orbit_required = ['ASCENDING', 'DESCENDING', 'BOTH']\n",
        "    if (ORBIT not in orbit_required):\n",
        "        raise ValueError(\"ERROR!!! Parameter ORBIT not correctly defined\")\n",
        "\n",
        "\n",
        "    format_required = ['LINEAR', 'DB']\n",
        "    if (FORMAT not in format_required):\n",
        "        raise ValueError(\"ERROR!!! FORMAT not correctly defined\")\n",
        "        \n",
        "    \n",
        "    \n",
        "    ###########################################\n",
        "    # 1. IMPORT COLLECTION\n",
        "    ###########################################\n",
        "    \n",
        "    s1 = ee.ImageCollection('COPERNICUS/S1_GRD_FLOAT') \\\n",
        "                .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
        "                .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
        "                .filter(ee.Filter.eq('resolution_meters', 10)) \\\n",
        "                .filter(ee.Filter.eq('platform_number', 'A')) \\\n",
        "                .filterDate(START_DATE, STOP_DATE) \\\n",
        "                .filterBounds(ROI)\n",
        "    \n",
        "    #########################\n",
        "    # 2. SELECT POLARIZATION\n",
        "    #########################:\n",
        "\n",
        "        # select orbit\n",
        "    if (ORBIT != 'BOTH'):\n",
        "      s1 = s1.filter(ee.Filter.eq('orbitProperties_pass', ORBIT))\n",
        "\n",
        "    if (RELATIVE_ORBIT_NUMBER != 'ANY'): \n",
        "      s1 =  s1.filter(ee.Filter.eq('relativeOrbitNumber_start', RELATIVE_ORBIT_NUMBER)) \n",
        "      \n",
        "    \n",
        "    if (POLARIZATION == 'VV'):\n",
        "      s1 = s1.select(['VV','angle'])\n",
        "    elif (POLARIZATION == 'VH'):\n",
        "      s1 = s1.select(['VH','angle'])\n",
        "    elif (POLARIZATION == 'VVVH'):\n",
        "      s1 = s1.select(['VV','VH','angle'])  \n",
        "      \n",
        "    ########################\n",
        "    # 3. CLIP TO ROI\n",
        "    ####################### \n",
        "    \n",
        "    # clip image to roi\n",
        "    if (CLIP_TO_ROI):\n",
        "        s1 = s1.map(lambda image: image.clip(ROI))\n",
        "              \n",
        "    ########################\n",
        "    # 7. FORMAT CONVERSION\n",
        "    ####################### \n",
        "    \n",
        "    if (FORMAT == 'DB'):\n",
        "        s1 = s1.map(lin_to_db)\n",
        "        \n",
        "        \n",
        "    return s1\n",
        "\n",
        "#@title Helper functions for export and testing\n",
        "\n",
        "def export(IMAGE_PREFIX, KERNEL_BUFFER, GEOMETRY):\n",
        "  \"\"\"Run the image export task.  Block until complete.\n",
        "  \"\"\"\n",
        "  task = ee.batch.Export.image.toCloudStorage(\n",
        "    image = image.select(params['BANDS']),\n",
        "    description = params['IMAGE_PREFIX'],\n",
        "    bucket = params['BUCKET'],\n",
        "    fileNamePrefix = params['FOLDER'] + '/' + params['IMAGE_PREFIX'],\n",
        "    region = params['GEOMETRY'].getInfo()['coordinates'],\n",
        "    scale = 10,\n",
        "    fileFormat = 'TFRecord',\n",
        "    maxPixels = 1e13,\n",
        "    formatOptions = {\n",
        "      'patchDimensions': params['KERNEL_SHAPE'],\n",
        "      'kernelSize': params['KERNEL_BUFFER'],\n",
        "      'compressed': True,\n",
        "      'maxFileSize': 104857600\n",
        "    }\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  # Block until the task completes.\n",
        "  print('Running image export to Cloud Storage...')\n",
        "  import time\n",
        "  while task.active():\n",
        "    time.sleep(30)\n",
        "\n",
        "  # Error condition\n",
        "  if task.status()['state'] != 'COMPLETED':\n",
        "    print('Error with image export.')\n",
        "  else:\n",
        "    print('Image export completed.')\n",
        "\n",
        "def prediction(params):\n",
        "  \"\"\"Perform inference on exported imagery, upload to Earth Engine.\n",
        "  \"\"\"\n",
        "\n",
        "  print('Looking for TFRecord files...')\n",
        "\n",
        "  # Get a list of all the files in the output bucket.\n",
        "  filesList = !gsutil ls 'gs://'{params['BUCKET']}'/'{params['FOLDER']}\n",
        "\n",
        "  # Get only the files generated by the image export.\n",
        "  exportFilesList = [s for s in filesList if params['IMAGE_PREFIX'] in s]\n",
        "\n",
        "  # Get the list of image files and the JSON mixer file.\n",
        "  imageFilesList = []\n",
        "  jsonFile = None\n",
        "  for f in exportFilesList:\n",
        "    if f.endswith('.tfrecord.gz'):\n",
        "      imageFilesList.append(f)\n",
        "    elif f.endswith('.json'):\n",
        "      jsonFile = f\n",
        "\n",
        "  # Make sure the files are in the right order.\n",
        "  imageFilesList.sort()\n",
        "\n",
        "  from pprint import pprint\n",
        "  pprint(imageFilesList)\n",
        "  print(jsonFile)\n",
        "\n",
        "  import json\n",
        "  # Load the contents of the mixer file to a JSON object.\n",
        "  jsonText = !gsutil cat {jsonFile}\n",
        "  # Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "  mixer = json.loads(jsonText.nlstr)\n",
        "  pprint(mixer)\n",
        "  patches = mixer['totalPatches']\n",
        "\n",
        "  # Get set up for prediction.\n",
        "  x_buffer = int(params['KERNEL_BUFFER'][0] / 2)\n",
        "  y_buffer = int(params['KERNEL_BUFFER'][1] / 2)\n",
        "\n",
        "  buffered_shape = [\n",
        "      params['KERNEL_SHAPE'][0] + params['KERNEL_BUFFER'][0],\n",
        "      params['KERNEL_SHAPE'][1] + params['KERNEL_BUFFER'][1]]\n",
        "\n",
        "  imageColumns = [\n",
        "    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32) \n",
        "      for k in BANDS\n",
        "  ]\n",
        "\n",
        "  imageFeaturesDict = dict(zip(params['BANDS'], imageColumns))\n",
        "\n",
        "  def parse_image(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n",
        "\n",
        "  def toTupleImage(inputs):\n",
        "    inputsList = [inputs.get(key) for key in params['BANDS']]\n",
        "    stacked = tf.stack(inputsList, axis=0)\n",
        "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "    #stacked = tf.reshape(tensor = stacked , shape = [NR_IMAGES, 32 , 32 ,len(BAND_MODE)])\n",
        "    return stacked\n",
        "\n",
        "   # Create a dataset from the TFRecord file(s) in Cloud Storage.\n",
        "  imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
        "  imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n",
        "  imageDataset = imageDataset.map(toTupleImage).batch(1)\n",
        "\n",
        "  # Perform inference.\n",
        "  print('Running predictions...')\n",
        "  predictions = model.predict(imageDataset, steps=patches, verbose=1)\n",
        "  predictions = predictions[0]\n",
        "  #predictions = predictions.argmax(axis=3)\n",
        "  print(len(predictions))\n",
        "  print(predictions[0].shape)\n",
        " \n",
        "\n",
        "  print('Writing predictions...')\n",
        "  out_image_file = 'gs://' + params['BUCKET'] + '/' + params['FOLDER'] + '/' + params['MODEL_NAME'] + '.TFRecord'\n",
        "  writer = tf.io.TFRecordWriter(out_image_file)\n",
        "  patches = 0\n",
        "\n",
        "  for predictionPatch in predictions:\n",
        "    print('Writing patch ' + str(patches) + '...')\n",
        "    predictionPatch = predictionPatch[\n",
        "        x_buffer:x_buffer+params['KERNEL_SIZE'], y_buffer:y_buffer+params['KERNEL_SIZE'],:]\n",
        "\n",
        "    if params['POLARIZATION'] == 'VVVH':\n",
        "    # Create an example.\n",
        "      example = tf.train.Example(\n",
        "        features=tf.train.Features(\n",
        "          feature={\n",
        "            'VV': tf.train.Feature(\n",
        "                float_list=tf.train.FloatList(\n",
        "                    value=predictionPatch[:,:,0].flatten())),\n",
        "            'VH': tf.train.Feature(\n",
        "                float_list=tf.train.FloatList(\n",
        "                    value=predictionPatch[:,:,1].flatten()))\n",
        "          }\n",
        "        )\n",
        "      )\n",
        "    else:\n",
        "      example = tf.train.Example(\n",
        "        features=tf.train.Features(\n",
        "          feature={\n",
        "            params['POLARIZATION']: tf.train.Feature(\n",
        "                float_list=tf.train.FloatList(\n",
        "                    value=predictionPatch.flatten()))\n",
        "          }\n",
        "        )\n",
        "      )\n",
        "    # Write the example.\n",
        "    writer.write(example.SerializeToString())\n",
        "    patches += 1\n",
        "\n",
        "  writer.close()\n",
        "\n",
        "  # Start the upload.\n",
        "  out_image_asset = USER_ID + '/' + params['MODEL_NAME']\n",
        "  !earthengine upload image --asset_id={out_image_asset} {out_image_file} {jsonFile}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT8ycmzClYwf"
      },
      "source": [
        "# Data Prep\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IlgXu-vcUEY"
      },
      "source": [
        "#Test image area \n",
        "\n",
        "#roi\n",
        "geometry =  ee.Geometry.Polygon(\n",
        "        [[[103.08000490033993, -2.8225068747308946],\n",
        "          [103.08000490033993, -2.9521181019620673],\n",
        "         [103.29217836225399, -2.9521181019620673],\n",
        "         [103.29217836225399, -2.8225068747308946]]])\n",
        "\n",
        "geometry2 =     ee.Geometry.Polygon(\n",
        "        [[[103.28423388261817, -2.666639235594898],\n",
        "          [103.28423388261817, -2.7983252476718885],\n",
        "          [103.47786791582129, -2.7983252476718885],\n",
        "          [103.47786791582129, -2.666639235594898]]])\n",
        "\n",
        "#Parameters\n",
        "params = {   # GCS bucket\n",
        "           'START_DATE': '2021-12-01', \n",
        "            'STOP_DATE': '2021-12-31',        \n",
        "            'ORBIT': 'DESCENDING',\n",
        "            'RELATIVE_ORBIT_NUMBER':18, \n",
        "            'POLARIZATION': 'VVVH',\n",
        "            'ROI':    geometry,\n",
        "            'FORMAT': 'DB',\n",
        "            'CLIP_TO_ROI': True,\n",
        "            'EXPORT': 'GCS',\n",
        "            'BUCKET' : 'senalerts_dl3',\n",
        "            'DRIVE' : '/content/drive',\n",
        "            'FOLDER' : 'deSpeckNet',\n",
        "            'USER_ID' : 'users/adugnagirma',\n",
        "            'IMAGE_PREFIX' : 'deSpeckNet_TEST_PATCH_v3_',\n",
        "          # Should be the same bands selected during data prep\n",
        "            'BANDS': ['VV', 'VH'],\n",
        "            'RESPONSE_TR' : ['VV_median', 'VH_median'],\n",
        "            'RESPONSE_TU' : ['VV', 'VH'],\n",
        "            'MASK' : ['VV_mask', 'VH_mask'],\n",
        "            'KERNEL_SIZE' : 256,\n",
        "            'KERNEL_SHAPE' : [256, 256],\n",
        "            'KERNEL_BUFFER' : [128, 128],\n",
        "            'MODEL_NAME': 'tune'\n",
        "            }\n",
        "\n",
        "#process Sentinel 1 image collection\n",
        "s1_processed = s1_prep(params)\n",
        "bandNames = s1_processed.first().bandNames().remove('angle')\n",
        "s1_processed = s1_processed.select(bandNames)\n",
        "print('Number of images in the collection: ', s1_processed.size().getInfo())\n",
        "\n",
        "image = s1_processed.first()\n",
        "# Specify inputs (Sentinel-1 bands) to the model and the response variable.\n",
        "BANDS = image.bandNames().getInfo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize"
      ],
      "metadata": {
        "id": "PBazY6TX3bWQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1fmcU0Pxyf5"
      },
      "source": [
        "\n",
        "# Use folium to visualize the imagery.#\n",
        "mapid = image.getMapId({'bands':BANDS[0], 'min': -20, 'max':0})\n",
        "map = folium.Map(location=[-2.6145179357243027, 103.46795961225435])\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='Sentinel-1 12 day mosaic composite',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "4flKnkuJ3fQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "MODEL_DIR = 'gs://' + params['BUCKET'] + '/' + params['FOLDER'] + '/' + params['MODEL_NAME']\n",
        "#custom_objects={'TransformerBlock': TransformerBlock}\n",
        "model = tf.keras.models.load_model(MODEL_DIR)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4PkNCE4UHrIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Export and Inference"
      ],
      "metadata": {
        "id": "Lhg6_pL63sJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the export. (Run the export only once)\n",
        "export(image,params)\n",
        "# Run the prediction.\n",
        "prediction(params)"
      ],
      "metadata": {
        "id": "UFgFMMlxl_re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize"
      ],
      "metadata": {
        "id": "AoKrqlO_36h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_image = ee.Image(params['USER_ID'] + '/' + params['MODEL_NAME'])\n",
        "\n",
        "map.add_child(folium.LayerControl())\n",
        "map\n",
        "#out_image = out_image.arrayArgmax()\n",
        "mapid = out_image.getMapId({'min':-20,'max':0})\n",
        "mapid_2 = image.getMapId({'bands':BANDS[0], 'min': -20, 'max':0})\n",
        "map = folium.Map(location=[-2.6145179357243027, 103.46795961225435])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid_2['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='original image',\n",
        "  ).add_to(map)\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='Filtered image',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "id": "o_iH-qmY8FXz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}